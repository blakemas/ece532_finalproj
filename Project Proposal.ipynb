{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods to exploit structured sparsity\n",
    "*Authors: Scott Sievert, Blake Mason, Ian Kinesella*\n",
    "\n",
    "## Brief overview\n",
    "We plan to explore the use of regularizers to enfore structured sparsity in estimation. The methods can be used to reflect prior knowledge on a dataset.\n",
    "\n",
    "In class, we'll cover LASSO. We would like to extend this to explore the space of other regularizers which can be used to further reflect more complex structure in the signal.\n",
    "\n",
    "For this, we would like to implement the following algorithms:\n",
    "\n",
    "* [LASSO method]\n",
    "* [group lasso]\n",
    "* [sparse group lasso]\n",
    "* [sparse overlapping set lasso]\n",
    "\n",
    "We plan to investigate these models to better understand under which conditions it becomes appropriate to apply them and their characteristics.\n",
    "\n",
    "[LASSO method]:https://en.wikipedia.org/wiki/Least_squares#Lasso_method\n",
    "[group lasso]:http://www.jstor.org/stable/20203811?seq=1#page_scan_tab_contents\n",
    "[sparse group lasso]:http://arxiv.org/abs/1001.0736\n",
    "[sparse overlapping set lasso]:http://papers.nips.cc/paper/4891-sparse-overlapping-sets-lasso-for-multitask-learning-and-its-application-to\n",
    "[l0_norm]:http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=4541671&url=http%3A%2F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D4541671"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core concepts\n",
    "In general, some measurements are known for an underdetermined system. LASSO determines a solution by adding a regularization term and estimates a solution accordingly. \n",
    "\n",
    "$$y = Ax$$ where $y \\in R^m, A\\in R^{m, n}$ and $x \\in R^n$ where $m \\ll n$. In general, this equation has infinitely many solutions and can not be solved. However, by assuming certain structure in a unique $x$ can be found.\n",
    "\n",
    "What structure is assumed about $x$? Do we assume that $x$ have very little energy? Do we assume that $x$ has very few non-zero elements? Do we assume some mix of the two?\n",
    "\n",
    "The energy in a system can be represented by the $\\ell_2$ [norm] and the number of non-zero coefficients can be represented by the $\\ell_0$ norm.\n",
    "\n",
    "It should be noted that including an $\\ell_0$ regularization term is NP-hard and non-convex. Qouting [\"Approximate L0 constrained Non-negative Matrix and Tensor Factorization\"],\n",
    "\n",
    "> In general, solving for a given L0 norm is an NP hard problem thus convex relaxation regularization by the L1 norm is often considered\n",
    "\n",
    "meaning that $\\ell_1$ regularization is a tractable problem and that mimics $\\ell_0$ regularization.\n",
    "\n",
    "Then we can say one of the following: \n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\widehat{x} &= \\arg \\min_x ||y - Ax||_2^2 + \\lambda||x||_1\\\\\n",
    "\\widehat{x} &= \\arg \\min_x ||y - Ax||_2^2 + \\lambda||x||_2\\\\\n",
    "\\widehat{x} &= \\arg \\min_x ||y - Ax||_2^2 + \\lambda_1 ||x||_1 + \\lambda_2||x||_2\n",
    "\\end{aligned}$$\n",
    "\n",
    "$\\ell_2$ regularization tends to minimize the energy in the solution, leading to a solution that contains many small coefficients.\n",
    "\n",
    "$\\ell_1$ regularization tends to give more [sparse] solutions. This regularization term can be seen as an approximation for a $\\ell_0$ regularization term, which minimizes the number of non-zero enteries.\n",
    "\n",
    "\n",
    "### Goal\n",
    "We intend to implement a framework like [SPARSA] or [FISTA] (rather than using third party software like [cvxpy]) which would avail us to a variety of regularizers by implementing their prox operators. This Lab would provide students with an understanding the mathematics behind differentregularizers and what problems they are useful for solving.\n",
    "\n",
    "[FISTA]:http://mechroom.technion.ac.il/~becka/papers/71654.pdf\n",
    "[SPARSA]:http://www.lx.it.pt/~mtf/SpaRSA/IEEE_TSP_2009_Wright_Nowak_Figueiredo.pdf\n",
    "[cvxpy]:http://www.cvxpy.org/en/latest/\n",
    "[sparse]:https://en.wikipedia.org/wiki/Sparse_matrix\n",
    "[norm]:https://en.wikipedia.org/wiki/Norm_(mathematics)\n",
    "[\"Approximate L0 constrained Non-negative Matrix and Tensor Factorization\"]:http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.89.3364"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n",
    "We are open to suggestions of interesting and relevant real worl datasets for which applying these different modeling would be appropriate. Additionally, there are a wealth of datasets available at [awesome-public-datasets]. This repo includes datasets in the realms of weather, sports, and goverment data. We are confident that we could find some real world data to apply to this problem.\n",
    "\n",
    "[awesome-public-datasets]:https://github.com/caesar0301/awesome-public-datasets\n",
    "\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```latex\n",
    "% Group lasso\n",
    "@article{meier2008,\n",
    "  title={The group lasso for logistic regression},\n",
    "  author={Meier, Lukas and Van De Geer, Sara and B{\\\"u}hlmann, Peter},\n",
    "  journal={Journal of the Royal Statistical Society: Series B (Statistical Methodology)},\n",
    "  volume={70},\n",
    "  number={1},\n",
    "  pages={53--71},\n",
    "  year={2008},\n",
    "  publisher={Wiley Online Library}\n",
    "}\n",
    "\n",
    "% Sparse Group lasso\n",
    "@article{friedman2010,\n",
    "  title={A note on the group lasso and a sparse group lasso},\n",
    "  author={Friedman, Jerome and Hastie, Trevor and Tibshirani, Robert},\n",
    "  journal={arXiv preprint arXiv:1001.0736},\n",
    "  year={2010}\n",
    "}\n",
    "\n",
    "% Sparse overlapping set lasso\n",
    "@inproceedings{rao2013,\n",
    "  title={Sparse overlapping sets lasso for multitask learning and its application to fMRI analysis},\n",
    "  author={Rao, Nikhil and Cox, Christopher and Nowak, Rob and Rogers, Timothy T},\n",
    "  booktitle={Advances in neural information processing systems},\n",
    "  pages={2202--2210},\n",
    "  year={2013}\n",
    "}\n",
    "\n",
    "% L0 norm\n",
    "@MISC{l0_norm,\n",
    "    author = {Morten MÃ¸rup and Kristoffer Hougaard Madsen and Lars Kai Hansen and Informatics},\n",
    "    title = {Approximate L0 constrained Non-negative Matrix and Tensor Factorization},\n",
    "    year = {}\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
